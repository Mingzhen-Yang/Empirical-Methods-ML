{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with [*Missing* Data](https://en.wikipedia.org/wiki/Missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most online _machine learning_ classes you are taught that when your data set is **incomplete** you can either:\n",
    "1. Erase the corresponding rows with missing cells; or\n",
    "2. _Impute_ (fill) the sample average of each column into those missing cells.\n",
    "\n",
    "It turns out that the second option would require stronger assumptions than the first. If the observations are **missing completely at random** and your sample is i.i.d., the first option is harmless for large data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding [Categorical Variables](https://en.wikipedia.org/wiki/Categorical_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’» Consider the ```hprice3``` data set from the ```wooldridge``` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## installing the 'wooldridge' package if not previously installed\n",
    "if (!require(wooldridge)) install.packages('wooldridge')\n",
    "\n",
    "data(hprice3)\n",
    "\n",
    "## Obs:   321\n",
    "\n",
    "##  1. year                     1978, 1981\n",
    "##  2. age                      age of house\n",
    "##  3. agesq                    age^2\n",
    "##  4. nbh                      neighborhood, 1 to 6\n",
    "##  5. cbd                      dist. to central bus. dstrct, feet\n",
    "##  6. inst                     dist. to interstate, feet\n",
    "##  7. linst                    log(inst)\n",
    "##  8. price                    selling price\n",
    "##  9. rooms                    # rooms in house\n",
    "## 10. area                     square footage of house\n",
    "## 11. land                     square footage lot\n",
    "## 12. baths                    # bathrooms\n",
    "## 13. dist                     dist. from house to incin., feet\n",
    "## 14. ldist                    log(dist)\n",
    "## 15. lprice                   log(price)\n",
    "## 16. y81                      =1 if year = 1981\n",
    "## 17. larea                    log(area)\n",
    "## 18. lland                    log(land)\n",
    "## 19. linstsq                  linst^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’» Variables ```y81```, ```rooms```, and ```nbh``` are examples of <ins>categorical</ins> variables. In Econometrics, ```y81``` is called a standard dummy variable, ```rooms``` is called an _ordered_ categorical variable, ```hbh``` is called an _unordered_ categorical variable. Both ```rooms``` and ```nbh``` have _multiple_ categories. The fucntion ```as.factor()``` with option ```ordered=TRUE``` and ```ordered=FALSE``` (default) will allow us to handle them accordingly in all analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## without using the 'as.factor' function\n",
    "attach(hprice3)\n",
    "no.factor <- data.frame(y81=y81,rooms=rooms,nbh=nbh)\n",
    "summary(no.factor)\n",
    "detach(hprice3)\n",
    "\n",
    "## using the 'as.factor' function\n",
    "attach(hprice3)\n",
    "yes.factor <- data.frame(y81=factor(y81),\n",
    "                         rooms=factor(rooms,ordered=TRUE),\n",
    "                         nbh=factor(nbh,ordered=FALSE)\n",
    "                         )\n",
    "summary(yes.factor)\n",
    "detach(hprice3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’» The default behavior in regression is to transformed ordered and unordered categorical variable with multiple categories into a set of $c-1$ dummy variables and include them as regressors, where $c$ represents the number of categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols <- lm(lprice ~ lland + larea + I(log(cbd)) +\n",
    "                   as.factor(y81) + as.factor(rooms) + as.factor(nbh) +\n",
    "                   linst + linstsq + ldist + baths + age + agesq,\n",
    "          data=hprice3)\n",
    "\n",
    "## installing the 'lmtest', 'sandwich' packages if not previously installed\n",
    "## installing the 'lmtest' package if not previously installed\n",
    "if (!require(lmtest)) install.packages('lmtest')\n",
    "if (!require(sandwich)) install.packages('sandwich')\n",
    "\n",
    "## turning 'off' scientific notation\n",
    "options(scipen = 999) \n",
    "\n",
    "## calculating standard t-statistics for 'significance'\n",
    "coeftest(ols, vcov = vcovHC, type = \"HC1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’» In many machine learning algorithms you are required to provide the design (model) matrix, $\\mathbf{X}$ (*without* and intercept), and response vector, $\\mathbf{y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X <- model.matrix(ols)[,-1]\n",
    "dim(X)\n",
    "colnames(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“Œ It is good practice to define categorical variables _outside_ the model formula/fitting. When doing this, one can easily change the 'base' category using the ```relevel()``` function along with the ```within()``` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including [Interaction Terms](https://en.wikipedia.org/wiki/Interaction_(statistics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previously fitted model we included ```linstsq``` and ```agesq``` as predictors. These correspond to the squared of the original predictors ```linst``` and ```age```. In economics we include such predictors to account for increasing/decreasing returns to scale in modelling. Since $\\texttt{linst}^2=\\texttt{linst}\\times\\texttt{linst}$ and $\\texttt{age}^2=\\texttt{age}\\times\\texttt{age}$, one can think of them as a specific type of interaction terms (products with themselves)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
